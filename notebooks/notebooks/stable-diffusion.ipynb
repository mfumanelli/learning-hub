{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8e4382d",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/cover.png\" alt=\"cover\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36df534b",
   "metadata": {},
   "source": [
    "# Accelerate Stable Diffusion Model Using Speedster + New TensorRT 8.6 Release and Gradio App Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618b51be-63e5-4fc3-bfc1-70dd947cd79a",
   "metadata": {},
   "source": [
    "#### 🚀 Welcome to this notebook focused on optimizing Stable Diffusion using Speedster 🚀\n",
    "\n",
    "### Goal\n",
    "The goal is to optimize the performance of a Stable Diffusion model using Speedster and the latest TensorRT version, to obtain an inference model that runs ~2 times faster than the original one. After that, we will show you how easy it is to integrate an optimized model in a Gradio application, so we will develop a game using Gradio and the accelerated model. The game we create will be called *guess the Pokémon*, the user will have to identify the name of the Pokémon generated using the optimized Stable Diffusion model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ca852-9e20-440c-a073-029ad0baf663",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/sd-cover.png\" alt=\"cover\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd4102f",
   "metadata": {},
   "source": [
    "### Stable Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562dced5",
   "metadata": {},
   "source": [
    "Stable Diffusion, which was released in 2022, is a text-to-image model that is mainly utilized for generating images based on textual descriptions.\n",
    "\n",
    "Stable Diffusion consists of three main components: \n",
    "* **a text-understanding component** that uses a Transformer language model to translate text into a numeric representation\n",
    "* **an image generator** that includes an image information creator and an image decoder \n",
    "* **an autoencoder decoder** that produces the final image\n",
    "\n",
    "The image generator works in the latent space and gradually processes the information to generate high-quality images, with the UNet neural network and scheduling algorithm as its components. The image decoder uses the processed information array to produce the final pixel image. Speedster's main focus for model acceleration is the conditional U-Net architecture utilized for denoising the latent component of the encoded image. The reason for this emphasis is that UNet is executed multiple times based on the num_inference_steps hyperparameter, which is usually set to 50 by default. As a result, the computational cost of UNet far outweighs the impact of the other two model components, which are only executed once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87325a48-409c-4ec1-aa8a-67ffb75ae716",
   "metadata": {},
   "source": [
    "<center><img src=\"../imgs/stab1.jpg\" alt=\"stab1\" width=\"600\" height=\"400\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda1ba83-8353-472b-abfc-e447c43420f7",
   "metadata": {},
   "source": [
    "<center><small style=\"font-size: 12px;\">Image taken from The Illustrated Stable Diffusionb log by Jay Alammar.</small></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb78874-d878-4bb7-ba0b-1d6095072498",
   "metadata": {},
   "source": [
    "<center><img src=\"../imgs/stab2.jpg\" alt=\"stab2\"  width=\"600\" height=\"400\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86ba113-108e-4537-8197-9c59662864b4",
   "metadata": {},
   "source": [
    "<center><small style=\"font-size: 12px;\">Image taken from The Illustrated Stable Diffusion blog by Jay Alammar.</small></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b088504",
   "metadata": {},
   "source": [
    "### Speedster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7758a909-fdda-40d0-947a-9da41ab8ffce",
   "metadata": {},
   "source": [
    "Nebuly's [Speedster](https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/speedster) is an **open-source** module that enables fast AI inference through just a few lines of code. The module automatically applies state-of-the-art optimization techniques to maximize the hardware's physical inference speed-up, including latency, throughput, and model size on a single machine.\n",
    "\n",
    "To get started, you can refer to the [getting started guide](https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/speedster) for five different input model frameworks supported by Speedster, which are PyTorch, Hugging Face Transformers, Hugging Face Diffusers, TensorFlow/Keras, and ONNX.\n",
    "\n",
    "In this notebook, we will delve into the details of Stable Diffusion and the Speedster algorithm. We will learn how to implement Speedster in Python and use it to optimize Stable Diffusion.\n",
    "\n",
    "In addition to optimization techniques, we will also create a Gradio application to interact with our accelerated model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10752f50-4f7f-452b-ab07-e5eaba2fa5b7",
   "metadata": {},
   "source": [
    "<center><img src=\"../imgs/neb.jpg\" alt=\"nebuly\" width=\"600\" height=\"400\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857b4230-6e54-474b-a521-d0a5a58b06e0",
   "metadata": {},
   "source": [
    "<center><small style=\"font-size: 12px;\">Image taken from Nebuly's website.</small></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e71c6f",
   "metadata": {},
   "source": [
    "## Install and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44e3366-38a5-4f02-880f-d339437ef492",
   "metadata": {},
   "source": [
    "Before we dive into the analysis, we need to make sure that we have all the necessary tools to execute the code. In this section, we will install the required packages and libraries to ensure a smooth and error-free run of the notebook. These packages include torch, Speedster and some Hugging Face libraries. Once we have installed the packages, we will import them into the notebook and get ready to use them in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d872948e-bff3-462d-b3d5-c18daff6305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install accelerate torch datasets diffusers gradio speedster --quiet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ea8891",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m nebullvm.installers.auto_installer --frameworks diffusers --compilers all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b5cbfa-b4d7-4913-90a0-7dbf8898f146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "from speedster import optimize_model, save_model, load_model\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "from random import randrange\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b906350-54e1-468e-a186-8de10fb6400d",
   "metadata": {},
   "source": [
    "## Environment Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed1ed43-a961-49c6-b63f-d3294123539c",
   "metadata": {},
   "source": [
    "![ChessUrl](https://media.giphy.com/media/rAm0u2k17rM3e/giphy.gif \"env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5451bf78",
   "metadata": {},
   "source": [
    "In order to make everything work, we need to check that the environment meets the necessary requirements. In particular, to optimize a model of the Hugging Face Diffusers library you need to have `CUDA>=12` and `tensorrt>=8.6.0`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eb8ff0",
   "metadata": {},
   "source": [
    "From TensorRT 8.6, all the tensorrt pre-built wheels released by nvidia support only `CUDA>=12.0`. Speedster will install `tensorrt>=8.6.0` automatically in the auto-installer only if it detects `CUDA>=12.0`, otherwise it will install `tensorrt==8.5.3.1`. In that case, you will have to upgrade your CUDA version and then to upgarde tensorrt to 8.6.0 or above to execute this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e53514",
   "metadata": {},
   "source": [
    "First of all, Let's check the CUDA version installed on the machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecc389f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cuda_version = subprocess.check_output([\"nvidia-smi\"])\n",
    "    cuda_version = int(cuda_version.decode(\"utf-8\").split(\"\\n\")[2].split(\"|\")[-2].split(\":\")[-1].strip().split(\".\")[0])\n",
    "    assert cuda_version >= 12, (\"This notebook requires CUDA>=12.0 to be executed, please upgrade your CUDA version.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7c09c9",
   "metadata": {},
   "source": [
    "If you have `CUDA<12.0`, you can upgrade it at this link: https://developer.nvidia.com/cuda-downloads. The installation is very simple, you only have to select the characteristics of your environment and copy and paste the commands provided by Nvidia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec5858a",
   "metadata": {},
   "source": [
    "Then, let's check the tensorrt version installed on the platform. Stable Diffusion optimization is supported starting from `tensorrt==8.6.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81f2ed3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt\n",
    "from nebullvm.tools.utils import check_module_version\n",
    "\n",
    "assert check_module_version(tensorrt, \"8.6.0\"), (\"This notebook can be run only with tensorrt>=8.6.0, if using an older version you could have issues during the optimization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c697ded2",
   "metadata": {},
   "source": [
    "If you have an older version, after ensuring you have `CUDA>=12.0` installed, you can upgrade your TensorRT version by running:\n",
    "```\n",
    "! pip install -U tensorrt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0638a5-19cc-4e5b-b4d4-766c197358da",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eddf854-012e-49fb-9b2f-0234decc91b3",
   "metadata": {},
   "source": [
    "The data that will be used for analysis and modeling are derived from the [Bulbagarden](https://bulbapedia.bulbagarden.net/wiki/List_of_Pok%C3%A9mon_by_name) website and consists of a small dataset with two columns, one with the names of the Pokémon and the other with their descriptions.\n",
    "\n",
    "You can get the data from [Hugging Face](https://huggingface.co/datasets/mfumanelli/pokemon-description-xs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19474b8-b2b8-4c0e-94e1-46852b841d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"mfumanelli/pokemon-description-xs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4b76565-9cc7-47c3-be93-790d4c198041",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b91619e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>it's a blue and green Pokémon. It has a seed o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pikachu</td>\n",
       "      <td>it's a yellow and black Pokémon. It's a creatu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name                                        description\n",
       "0  Bulbasaur  it's a blue and green Pokémon. It has a seed o...\n",
       "1    Pikachu  it's a yellow and black Pokémon. It's a creatu..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbef81d6-d439-4892-8760-16571eb206ff",
   "metadata": {},
   "source": [
    "![ChessUrl](https://media.giphy.com/media/I2nZMy0sI0ySA/giphy.gif \"chess\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575f597f-ef20-411f-b241-6c57343debe2",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67523b45-08df-4170-89c2-758cc3e1d14d",
   "metadata": {},
   "source": [
    "First of all we have to choose the version of the Stable Diffusion model we want to optimize, Speedster officially supports the most used versions:\n",
    "\n",
    "* [CompVis/stable-diffusion-v1-4](https://huggingface.co/CompVis/stable-diffusion-v1-4)\n",
    "* [runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5)\n",
    "* [stabilityai/stable-diffusion-2-1-base](https://huggingface.co/stabilityai/stable-diffusion-2-1-base)\n",
    "* [stabilityai/stable-diffusion-2-1](https://huggingface.co/stabilityai/stable-diffusion-2-1)\n",
    "\n",
    "Other Stable Diffusion versions from the [Diffusers library](https://github.com/huggingface/diffusers) should work but have never been officially tested. \n",
    "\n",
    "⚠️ If you try a version not included among these and it works, please feel free to report it to us on [Discord](https://discord.com/invite/RbeQMu886J) so we can add it to the list of supported versions. If you try a version that does not work, you can open an issue and possibly a PR on [GitHub](https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/speedster) ⚠️\n",
    "\n",
    "In this notebook, we'll be utilizing the `Stable-Diffusion-v1-4` checkpoint. This checkpoint was initially based on the `Stable-Diffusion-v1-2` checkpoint's weights and subsequently fine-tuned for 225k steps at a resolution of 512x512 using \"laion-aesthetics v2 5+\" dataset, with 10% of text-conditioning removed to enhance classifier-free guidance sampling.\n",
    "\n",
    "**NOTE**: If you want to run the `stable-diffusion-2-1` version of Stable Diffusion, you need a GPU with a minimum of 22GB memory. If your GPU has less than 22GB memory, you can opt for other versions of the model, such as `stable-diffusion-2-1-base`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60d40675-f2d6-466b-873b-fedff54ada67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"CompVis/stable-diffusion-v1-4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdbb1ac-c0a7-4449-9874-0a4047a31570",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a87ba42-851e-4dd3-b257-2384cf1cb272",
   "metadata": {},
   "source": [
    "Using Speedster's latest API, there are two options to enhance the speed of your models. The first option allows you to accelerate your models without compromising accuracy, whereas the second option lets you further increase their speed by specifying a desired level of accuracy or precision to trade-off. To achieve this acceleration, Speedster utilizes several optimization techniques, including deep learning compilers (in both options), quantization, and half accuracy, among others (in the second option).\n",
    "\n",
    "Here are the outcomes achieved for Stable Diffusion on the A10 GPU (the GPU that we will use) and on the 3090Ti:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd15de3-bd42-4d48-8000-9893f66151ac",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/sd-benchmarks.png\" alt=\"cover\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6448eb-ba8d-42ae-bedc-aa0ec1fd41d5",
   "metadata": {},
   "source": [
    "We conducted tests on each GPU, evaluating the performance of the four most commonly utilized versions of Stable Diffusion. We compared the performance of the base version in fp16 with the version utilizing xformers and the speedster-compiled model. Our findings demonstrate that the optimized attention algorithm implemented within xformers delivers considerably better performance than the base model, particularly for the most complex model (the 2.1). Moreover, Speedster enhances the model's speed even further. In fact, the latest version of TensorRT outperforms both the base version and the one that utilizes xformers in all tested cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acf8c77-76df-4b9a-aca6-518513b44745",
   "metadata": {},
   "source": [
    "When utilizing Speedster to optimize Stable Diffusion models from Hugging Face's Diffusers library, two easy steps must be followed:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6589671e-74bb-4599-a4ac-70a54f027379",
   "metadata": {},
   "source": [
    "1) Once you have selected and downloaded the desired model, generate a small set of sample input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a0c899f-8990-4fb2-b790-6605e0738069",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = data.description[0:5].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2c6577-fe6f-4625-a8d7-57b9a08eb553",
   "metadata": {},
   "source": [
    "2) Run the optimization by specifying as arguments: \n",
    "* **Model**\n",
    "* **Input data**\n",
    "* **Optimization time** specify whether to limit or not\n",
    "* **Compilers to exclude** depending on hardware and model, certain compilers may be unsuitable\n",
    "* **Acceptable level of accuracy loss** during optimization, can be set to zero as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387df72a-bbf7-4555-830a-f47f60031cd0",
   "metadata": {},
   "source": [
    "**Please note**: Optimization of stable diffusion requires **a lot of RAM**. If you are running this notebook on google colab, make sure to use the high RAM option, otherwise the kernel may crash. If the kernel crashes also when using the high RAM option, please try adding \"torchscript\" to the ignore_compilers list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f3c30a-094d-4db7-a767-869095e13fc3",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025537b7-dab7-48e9-8ffd-7d8f99981198",
   "metadata": {},
   "source": [
    "Let's optimize the model on a single **A10 GPU**, note that on GPU we load by default the model in half precision, because it's faster and lighter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4d798f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a63b5af-c43b-4b09-9fae-44d6bd93e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == \"cuda\":\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_id, revision='fp16', torch_dtype=torch.float16)\n",
    "else:\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_id)\n",
    "\n",
    "pipe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809bfd2f-75b4-45f0-90c1-bc122810e8cf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimized_model = optimize_model(\n",
    "    model=pipe,\n",
    "    input_data=input_data,\n",
    "    optimization_time=\"unconstrained\",\n",
    "    ignore_compilers=[\"torch_tensor_rt\", \"tvm\"],  # TensorRT from the torch pipeline has some issues with Stable Diffusion, so we are going to skip it.\n",
    "    metric_drop_ths=0.2,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ee4f47-a67b-4307-ad97-69e0582028e9",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/output-stable-diffusion.png\" alt=\"cover\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f06958-0610-48dd-88db-72faff400aa1",
   "metadata": {},
   "source": [
    "As can be seen, the compiler that allows for greater acceleration of the model is TensorRT. Speedster has integrated the latest release of TensorRT, [**TensorRT v8.6.0**](https://github.com/NVIDIA/TensorRT/releases/tag/v8.6.0), which was recently made available by Nvidia.\n",
    "\n",
    "In essence, TensorRT optimizes a model's mathematical coordinates to strike a balance between the smallest possible size and highest achievable accuracy for the intended system. In the latest release, one of the key updates is that now the demoDiffusion acceleration is supported out of the box in TensorRT without requiring the installation of additional plugins.\n",
    "\n",
    "Using Speedster has enormous advantages over using TensorRT directly: it allows us to compare different optimization tools based on the available hardware and software, it offers simple and intuitive usability, performing all steps automatically and it returns as output a directly usable model in a simple way, not a tensorRT engine that would need additional operations before being used in inference. \n",
    "\n",
    "The model has ~2 times acceleration. This value refers only to the speedup on the UNet. To actually see how the latency times change let's calculate benchmarks using the original model and the optimized one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11757fc6-de4b-42dc-a79e-a7685bd1c8cd",
   "metadata": {},
   "source": [
    "## Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed256ccb-ca4f-416a-bc80-f0893dc750b3",
   "metadata": {},
   "source": [
    "Let's run the prediction 10 times to calculate the average response time of the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65720eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompt = \"futuristic llama with a cyberpunk city on the background\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b886630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == \"cuda\":\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_id, revision='fp16', torch_dtype=torch.float16)\n",
    "else:\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_id)\n",
    "\n",
    "pipe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee63316-1d8f-43be-bf4d-5c58a264e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "times = []\n",
    "\n",
    "# Warmup for 2 iterations\n",
    "for _ in range(2):\n",
    "    with torch.no_grad():\n",
    "        final_out = pipe(test_prompt).images[0]\n",
    "\n",
    "# Benchmark\n",
    "for _ in range(8):\n",
    "    st = time.time()\n",
    "    with torch.no_grad():\n",
    "        final_out = pipe(test_prompt).images[0]\n",
    "    times.append(time.time()-st)\n",
    "original_model_time = sum(times)/len(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ffb3c00-fc85-4e20-8044-0af25e8eb45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average response time for original Stable Diffusion 1.4 on a A10 GPU: 4.100552409887314 s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average response time for original Stable Diffusion 1.4 on a A10 GPU: {original_model_time} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b060416d-1f65-487c-9dc0-66bf82d14346",
   "metadata": {},
   "source": [
    "While the average response of the optimized model turns out to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3bb530-34f0-443e-be3a-0889632aed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "\n",
    "for _ in range(2):\n",
    "    with torch.no_grad():\n",
    "        final_out = optimized_model(test_prompt).images[0]\n",
    "\n",
    "# Benchmark\n",
    "for _ in range(8):\n",
    "    st = time.time()\n",
    "    with torch.no_grad():\n",
    "        final_out = optimized_model(test_prompt).images[0]\n",
    "    times.append(time.time()-st)\n",
    "optimized_model_time = sum(times)/len(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "489beaeb-f26e-4197-9e7a-3bd0c5b7daa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average response time for optimized Stable Diffusion 1.4: 2.160187304019928 s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average response time for optimized Stable Diffusion 1.4: {optimized_model_time} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d620e672-12fd-453a-931e-4925ae702bf6",
   "metadata": {},
   "source": [
    "The entire model has been sped up by roughly two times, reducing the average response time from around 4 seconds to approximately 2 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e5d445-3b1a-4379-9a21-ff82b4cda08e",
   "metadata": {},
   "source": [
    "## Gradio App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13c459-6143-4815-9c3c-e8b4bb1b5767",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/neb_x_gradio.png\" alt=\"neb_gradio\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9780baf8-968c-4feb-9ea2-c4d242cd6233",
   "metadata": {},
   "source": [
    "In this section, we will show how to create a Gradio application that utilizes the **optimized Stable Diffusion model generated using Speedster**. \n",
    "\n",
    "This Gradio application will allow users to generate images of Pokémon based on the descriptions provided in the previously loaded dataset. Let's dive in and create our very own Pokémon generator using Stable Diffusion and Gradio!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586fd5e1-80c5-44e3-b713-f8cac6858a76",
   "metadata": {},
   "source": [
    "The initial stage involves creating an inference function that enables the generation of images based on a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "183475c2-a3d9-4454-ace0-264e99d81293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(prompt, steps, scale):\n",
    "    generator = torch.Generator(device=device)\n",
    "\n",
    "    if device == 'cuda':\n",
    "        with torch.autocast(device):\n",
    "            image = optimized_model(\n",
    "                f\"\"\"Cutest cartoon ever created: {prompt}\"\"\",\n",
    "                num_inference_steps=steps,\n",
    "                guidance_scale=scale,\n",
    "                generator=generator,\n",
    "            )\n",
    "    else:\n",
    "        image = optimized_model(\n",
    "            f\"\"\"Cutest cartoon ever created: {prompt}\"\"\",\n",
    "            num_inference_steps=steps,\n",
    "            guidance_scale=scale,\n",
    "            generator=generator,\n",
    "        )\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939efbcd-8325-46f8-83d9-7e57b05c4271",
   "metadata": {},
   "source": [
    "The function needs to be invoked with a randomly selected Pokémon description from the dataset as its input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3564c05-1402-4ee8-a52b-21ccb0d23ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pokemon():\n",
    "    seed = randrange(data.shape[0])\n",
    "    random_description = data.iloc[seed][\"description\"]\n",
    "    image = infer(random_description, 50, 7)\n",
    "\n",
    "    return image[0][0], seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa2b03a-c194-4145-93cc-690777fd6a2a",
   "metadata": {},
   "source": [
    "last but not least, let's make a function to get the name of the generated Pokémon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3db5f847-45d3-4584-9cf7-55ab1a24862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pokemon_name(seed):\n",
    "    return data.iloc[int(seed)][\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b96f511-ce6e-47c5-91dd-18e2fd75be0e",
   "metadata": {},
   "source": [
    "Here is some CSS code to improve the visual appearance of our application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5622bfea-ee45-409e-ba25-43fa567a25f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "css = \"\"\"\n",
    "        .gradio-container {\n",
    "            font-family: 'IBM Plex Sans', sans-serif;\n",
    "        }\n",
    "        .gr-button {\n",
    "            color: white;\n",
    "            border-color: black;\n",
    "            background: black;\n",
    "        }\n",
    "        input[type='range'] {\n",
    "            accent-color: black;\n",
    "        }\n",
    "        .dark input[type='range'] {\n",
    "            accent-color: #dfdfdf;\n",
    "        }\n",
    "        .container {\n",
    "            max-width: 730px;\n",
    "            margin: auto;\n",
    "            padding-top: 1.5rem;\n",
    "        }\n",
    "        #iamge {\n",
    "            min-height: 22rem;\n",
    "            margin-bottom: 15px;\n",
    "            margin-left: auto;\n",
    "            margin-right: auto;\n",
    "            border-bottom-right-radius: .5rem !important;\n",
    "            border-bottom-left-radius: .5rem !important;\n",
    "        }\n",
    "        #iamge>div>.h-full {\n",
    "            min-height: 20rem;\n",
    "        }\n",
    "        .details:hover {\n",
    "            text-decoration: underline;\n",
    "        }\n",
    "        .gr-button {\n",
    "            white-space: nowrap;\n",
    "        }\n",
    "        .gr-button:focus {\n",
    "            border-color: rgb(147 197 253 / var(--tw-border-opacity));\n",
    "            outline: none;\n",
    "            box-shadow: var(--tw-ring-offset-shadow), var(--tw-ring-shadow), var(--tw-shadow, 0 0 #0000);\n",
    "            --tw-border-opacity: 1;\n",
    "            --tw-ring-offset-shadow: var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color);\n",
    "            --tw-ring-shadow: var(--tw-ring-inset) 0 0 0 calc(3px var(--tw-ring-offset-width)) var(--tw-ring-color);\n",
    "            --tw-ring-color: rgb(191 219 254 / var(--tw-ring-opacity));\n",
    "            --tw-ring-opacity: .5;\n",
    "        }\n",
    "        .footer {\n",
    "            margin-bottom: 45px;\n",
    "            margin-top: 35px;\n",
    "            text-align: center;\n",
    "            border-bottom: 1px solid #e5e5e5;\n",
    "        }\n",
    "        .footer>p {\n",
    "            font-size: .8rem;\n",
    "            display: inline-block;\n",
    "            padding: 0 10px;\n",
    "            transform: translateY(10px);\n",
    "            background: white;\n",
    "        }\n",
    "        .dark .footer {\n",
    "            border-color: #303030;\n",
    "        }\n",
    "        .dark .footer>p {\n",
    "            background: #0b0f19;\n",
    "        }\n",
    "        .acknowledgments h4{\n",
    "            margin: 1.25em 0 .25em 0;\n",
    "            font-weight: bold;\n",
    "            font-size: 115%;\n",
    "        }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712447db-65a3-4f0c-b302-3f96375a3616",
   "metadata": {},
   "source": [
    "Lastly, we will develop and deploy the application. Moreover, it can be hosted on Hugging Face for a duration of 72 hours using: <p style=\"font-family:monospace\"> demo.launch(share=True)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153aaf85-f77d-49c8-bf55-8e25706bdb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks(css=css) as demo:\n",
    "    gr.HTML(\n",
    "        \"\"\"\n",
    "            <div style=\"text-align: center; max-width: 650px; margin: 0 auto;\">\n",
    "              <div\n",
    "                style=\"\n",
    "                  display: inline-flex;\n",
    "                  align-items: center;\n",
    "                  gap: 0.8rem;\n",
    "                  font-size: 1.75rem;\n",
    "                \"\n",
    "              >\n",
    "                <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20%\" height=\"20%\" viewBox=\"0 0 100 100\">>\n",
    "\t<path d=\"M 30 50\n",
    "\t\ta 1 1 1 0 1 40 0\n",
    "\t\th-12.5\n",
    "\t\ta 1 1 1 0 0 -15 0\n",
    "\t\tz\"\n",
    "\t\tfill=\"#f00\" stroke=\"#222\"\n",
    "\t></path>\n",
    "\t<circle\n",
    "\t\tcx=\"50\"\n",
    "\t\tcy=\"50\"\n",
    "\t\tr=\"5\"\n",
    "\t\tfill=\"#222\" stroke=\"#222\"\n",
    "\t></circle>\n",
    "\t<path d=\"M 30 50\n",
    "\t\ta 1 1 1 0 0 40 0\n",
    "\t\th-12.5\n",
    "\t\ta 1 1 1 0 1 -15 0\n",
    "\t\tz\"\n",
    "\t\tfill=\"#fff\" stroke=\"#222\"\n",
    "\t></path>\n",
    "</svg>\n",
    "                <h1 style=\"font-weight: 900; margin-bottom: 7px;\">\n",
    "                  Stable Diffusion Loves Pokémon\n",
    "                </h1>\n",
    "              </div>\n",
    "              <p style=\"margin-bottom: 20px; font-size: 94%\">\n",
    "                Stable Diffusion is a state-of-the-art text-to-image model that generates images from text, \n",
    "                in this demo it is used to generate Pokèmon from their description. <br></p>\n",
    "                <hr style=\"height:2px;border-width:0;color:gray;background-color:gray\">\n",
    "                <br>\n",
    "              <p align=\"left\" style=\"margin-bottom: 10px; font-size: 94%\">\n",
    "                <b>Instructions</b>: press the \"Generate a Pokémon!\" button to generate an image and try to see if you can guess the movie.\n",
    "                You can see if you guessed right by pressing the \"Tell me the name\" button.\n",
    "              </p>\n",
    "              </br>\n",
    "              <b>NOTE: If a completely black image is generated, it means that the NSFW checker has blocked the display of the output.</b>\n",
    "            </div>\n",
    "        \"\"\"\n",
    "    )\n",
    "    with gr.Group():\n",
    "        with gr.Box():\n",
    "            with gr.Row().style(mobile_collapse=False, equal_height=True):\n",
    "                b1 = gr.Button(\"Generate a Pokémon\")\n",
    "                b2 = gr.Button(\"Tell me the name\")\n",
    "            text = gr.Textbox(label=\"Name:\")\n",
    "            image = gr.Image(\n",
    "                label=\"Generated images\", show_label=False, elem_id=\"image\"\n",
    "            ).style(height=\"auto\")\n",
    "\n",
    "            seed = gr.Number(visible=False)\n",
    "\n",
    "            b1.click(generate_pokemon, inputs=None, outputs=[image, seed])\n",
    "            b2.click(pokemon_name, inputs=seed, outputs=text)\n",
    "\n",
    "demo.launch(share=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bd3be9-c1dc-42f0-bc6f-1ca9d1f9d8c7",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/gradio_app.png\" alt=\"cover\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd69a59-a5ac-4b98-b658-aac14917fe13",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a21ded-8aa7-4dfb-a460-315bec08b4d6",
   "metadata": {},
   "source": [
    "And here we are, Let's summarize what we saw in this notebook:\n",
    "* Stable Diffusion is a text-to-image model mainly used to generate images based on textual descriptions\n",
    "* Accelerating this model with Speedster is very simple and fast\n",
    "* Speedster also integrates the latest version of TensorRT for 🚀🚀🚀🚀  performance and ease of use\n",
    "* Using Speedster we achieve 2x faster model latency\n",
    "* Using a Speedster-optimized model within a Gradio application is straightforward, as we showed in our example with the **guess the Pokémon** application\n",
    "\n",
    "We hope this notebook will be useful to you, also you can find many more speedster use cases in [this repository](https://github.com/nebuly-ai/learning-hub/notebooks).\n",
    "\n",
    "Remember to join our [Discord community](https://discord.com/invite/RbeQMu886J) and if you are interested in AI optimization or if you liked this notebook please leave a star at our repo [Speedster](https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/speedster) 💕🌟!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de5970-a8cc-4f04-a3d6-6d273252f84d",
   "metadata": {},
   "source": [
    "![ChessUrl](https://media.giphy.com/media/slVWEctHZKvWU/giphy.gif \"env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4c72f5-5a9b-4bd5-838c-72971348a131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
